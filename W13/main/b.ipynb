{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"display: table; width: 100%; color: #034ea2; background:#ffffff ; line-height: 100px;  text-align: center;\" dir=\"rtl\">\n",
    "        <h2 style=\"display:table-cell;\">Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„Ù…ÙˆÙ†  </h2>\n",
    "        <h1 style=\"display:table-cell;\"> <b>ğŸ‘¨â€ğŸ’» Ø§ÙˆÙŠØ³ Ø§Ù„Ø­Ù…ÙˆØ¯ ğŸ‘¨â€ğŸ’»</b></h1>\n",
    "        <h2 style=\"display:table-cell;\">201811330</h2>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import snowballstemmer \n",
    "import arabicstopwords.arabicstopwords as stp\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopWords(sentence):\n",
    "    terms=[]\n",
    "    stopWords= set(stp.stopwords_list())\n",
    "    for term in sentence.split() : \n",
    "        if term not in stopWords :\n",
    "            terms.append(term)\n",
    "    return \" \".join(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = re.sub(\"[Ø¥Ø£Ù±Ø¢Ø§]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
    "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_stemmer = snowballstemmer.stemmer('arabic')\n",
    "def stem(sentence):\n",
    "    return \" \".join([ar_stemmer.stemWord(i) for i in sentence.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(text):\n",
    "    return stem(normalize(remove_stopWords(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„Ù…ÙˆÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>ÙƒØ§Ù† Ø§Ù„Ø¬Ùˆ ØºØ§Ø¦Ù…Ø§Ù‹ Ø¬Ø²Ø¦ÙŠØ§Ù‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>Ù†Ø£Ù…Ù„ Ø£Ù† ØªÙÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„ÙˆÙ…Ù†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>Ù‡Ù„ Ø£Ù†ØªÙ… Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø©</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                               raw_text\n",
       "0    d1  Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª\n",
       "1    d2            Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„Ù…ÙˆÙ†\n",
       "2    d3                                 ÙƒØ§Ù† Ø§Ù„Ø¬Ùˆ ØºØ§Ø¦Ù…Ø§Ù‹ Ø¬Ø²Ø¦ÙŠØ§Ù‹\n",
       "3    d4             Ù†Ø£Ù…Ù„ Ø£Ù† ØªÙÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„ÙˆÙ…Ù†\n",
       "4    d5                             Ù‡Ù„ Ø£Ù†ØªÙ… Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø©"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "docs_df = pd.DataFrame(columns=[\"docno\", \"raw_text\"])\n",
    "for filename in os.listdir(\"..\\\\mydata\"):\n",
    "    i+=1 \n",
    "    filepath = os.path.join(\"..\\\\mydata\", filename) \n",
    "    with open(filepath, \"r\") as file: \n",
    "        data = file.read()\n",
    "    docs_df.loc[len(docs_df)]=[f'd{i}',data]\n",
    "         \n",
    "pd.set_option('display.max_colwidth',150)\n",
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docno</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª</td>\n",
       "      <td>Ù…Ø­Ø§Ø¶Ø±Ù‡ Ø«Ø§Ù†ÙŠÙ‡ Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ø¹Ù„ÙˆÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„Ù…ÙˆÙ†</td>\n",
       "      <td>Ù…Ø­Ø§Ø¶Ø±Ù‡ Ù„ØºÙ‡ Ø¹Ø±Ø¨ÙŠÙ‡ Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹ Ù‚Ù„Ù…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>ÙƒØ§Ù† Ø§Ù„Ø¬Ùˆ ØºØ§Ø¦Ù…Ø§Ù‹ Ø¬Ø²Ø¦ÙŠØ§Ù‹</td>\n",
       "      <td>Ø§Ù„Ø¬Ùˆ ØºØ§Ø¡Ù… Ø¬Ø²Ø¡ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>Ù†Ø£Ù…Ù„ Ø£Ù† ØªÙÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„ÙˆÙ…Ù†</td>\n",
       "      <td>Ù†Ø§Ù…Ù„ ØªÙÙŠØ¯ Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹ Ù‚Ù„ÙˆÙ…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>Ù‡Ù„ Ø£Ù†ØªÙ… Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø©</td>\n",
       "      <td>Ø³Ø¹Ø¯Ø§Ø¡ ØªØ¬Ø±Ø¨Ù‡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docno                                               raw_text  \\\n",
       "0    d1  Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª   \n",
       "1    d2            Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„Ù…ÙˆÙ†   \n",
       "2    d3                                 ÙƒØ§Ù† Ø§Ù„Ø¬Ùˆ ØºØ§Ø¦Ù…Ø§Ù‹ Ø¬Ø²Ø¦ÙŠØ§Ù‹   \n",
       "3    d4             Ù†Ø£Ù…Ù„ Ø£Ù† ØªÙÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù‚Ù„ÙˆÙ…Ù†   \n",
       "4    d5                             Ù‡Ù„ Ø£Ù†ØªÙ… Ø³Ø¹Ø¯Ø§Ø¡ Ø¨Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø©   \n",
       "\n",
       "                                  text  \n",
       "0  Ù…Ø­Ø§Ø¶Ø±Ù‡ Ø«Ø§Ù†ÙŠÙ‡ Ù…Ù‚Ø±Ø± Ù†Ø¸Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ø¹Ù„ÙˆÙ…  \n",
       "1      Ù…Ø­Ø§Ø¶Ø±Ù‡ Ù„ØºÙ‡ Ø¹Ø±Ø¨ÙŠÙ‡ Ù„Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹ Ù‚Ù„Ù…  \n",
       "2                       Ø§Ù„Ø¬Ùˆ ØºØ§Ø¡Ù… Ø¬Ø²Ø¡ÙŠ  \n",
       "3        Ù†Ø§Ù…Ù„ ØªÙÙŠØ¯ Ù…Ù‚Ø±Ø± Ø·Ù„Ø§Ø¨ Ø¬Ø§Ù…Ø¹ Ù‚Ù„ÙˆÙ…  \n",
       "4                          Ø³Ø¹Ø¯Ø§Ø¡ ØªØ¬Ø±Ø¨Ù‡  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['text']=docs_df['raw_text'].apply(preProcessing)\n",
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ù…Ø­Ø§Ø¶Ø±Ù‡',\n",
       " 'Ø«Ø§Ù†ÙŠÙ‡',\n",
       " 'Ù…Ù‚Ø±Ø±',\n",
       " 'Ù†Ø¸Ù…',\n",
       " 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹',\n",
       " 'Ù…Ø¹Ù„ÙˆÙ…',\n",
       " 'Ù…Ø­Ø§Ø¶Ø±Ù‡',\n",
       " 'Ù„ØºÙ‡',\n",
       " 'Ø¹Ø±Ø¨ÙŠÙ‡',\n",
       " 'Ù„Ø·Ù„Ø§Ø¨',\n",
       " 'Ø¬Ø§Ù…Ø¹',\n",
       " 'Ù‚Ù„Ù…',\n",
       " 'Ø§Ù„Ø¬Ùˆ',\n",
       " 'ØºØ§Ø¡Ù…',\n",
       " 'Ø¬Ø²Ø¡ÙŠ',\n",
       " 'Ù†Ø§Ù…Ù„',\n",
       " 'ØªÙÙŠØ¯',\n",
       " 'Ù…Ù‚Ø±Ø±',\n",
       " 'Ø·Ù„Ø§Ø¨',\n",
       " 'Ø¬Ø§Ù…Ø¹',\n",
       " 'Ù‚Ù„ÙˆÙ…',\n",
       " 'Ø³Ø¹Ø¯Ø§Ø¡',\n",
       " 'ØªØ¬Ø±Ø¨Ù‡']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms=[]\n",
    "for doc in docs_df['text']:\n",
    "    for term in doc.split():\n",
    "        terms.append(term)\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ù…Ø­Ø§Ø¶Ø±Ù‡',\n",
       " 'Ø«Ø§Ù†ÙŠÙ‡',\n",
       " 'Ù…Ù‚Ø±Ø±',\n",
       " 'Ù†Ø¸Ù…',\n",
       " 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹',\n",
       " 'Ù…Ø¹Ù„ÙˆÙ…',\n",
       " 'Ù„ØºÙ‡',\n",
       " 'Ø¹Ø±Ø¨ÙŠÙ‡',\n",
       " 'Ù„Ø·Ù„Ø§Ø¨',\n",
       " 'Ø¬Ø§Ù…Ø¹',\n",
       " 'Ù‚Ù„Ù…',\n",
       " 'Ø§Ù„Ø¬Ùˆ',\n",
       " 'ØºØ§Ø¡Ù…',\n",
       " 'Ø¬Ø²Ø¡ÙŠ',\n",
       " 'Ù†Ø§Ù…Ù„',\n",
       " 'ØªÙÙŠØ¯',\n",
       " 'Ø·Ù„Ø§Ø¨',\n",
       " 'Ù‚Ù„ÙˆÙ…',\n",
       " 'Ø³Ø¹Ø¯Ø§Ø¡',\n",
       " 'ØªØ¬Ø±Ø¨Ù‡']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_terms=[]\n",
    "for d in terms :\n",
    "    if d not in unique_terms:\n",
    "        unique_terms.append(d)\n",
    "unique_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ù…Ø­Ø§Ø¶Ø±Ù‡': ['d1', 'd1', 'd2', 'd2'],\n",
       " 'Ø«Ø§Ù†ÙŠÙ‡': ['d1'],\n",
       " 'Ù…Ù‚Ø±Ø±': ['d1', 'd1', 'd4', 'd4'],\n",
       " 'Ù†Ø¸Ù…': ['d1'],\n",
       " 'Ø§Ø³ØªØ±Ø¬Ø§Ø¹': ['d1'],\n",
       " 'Ù…Ø¹Ù„ÙˆÙ…': ['d1'],\n",
       " 'Ù„ØºÙ‡': ['d2'],\n",
       " 'Ø¹Ø±Ø¨ÙŠÙ‡': ['d2'],\n",
       " 'Ù„Ø·Ù„Ø§Ø¨': ['d2'],\n",
       " 'Ø¬Ø§Ù…Ø¹': ['d2', 'd2', 'd4', 'd4'],\n",
       " 'Ù‚Ù„Ù…': ['d2'],\n",
       " 'Ø§Ù„Ø¬Ùˆ': ['d3'],\n",
       " 'ØºØ§Ø¡Ù…': ['d3'],\n",
       " 'Ø¬Ø²Ø¡ÙŠ': ['d3'],\n",
       " 'Ù†Ø§Ù…Ù„': ['d4'],\n",
       " 'ØªÙÙŠØ¯': ['d4'],\n",
       " 'Ø·Ù„Ø§Ø¨': ['d2', 'd4'],\n",
       " 'Ù‚Ù„ÙˆÙ…': ['d4'],\n",
       " 'Ø³Ø¹Ø¯Ø§Ø¡': ['d5'],\n",
       " 'ØªØ¬Ø±Ø¨Ù‡': ['d5']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index={}\n",
    "for i, doc in enumerate(docs_df['text']):\n",
    "    for t in terms:\n",
    "        if t not in index:\n",
    "            index[t] = []\n",
    "        if(t in doc):\n",
    "            index[t].append(docs_df.loc[i,'docno'])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_operators = {'AND', 'OR'}\n",
    "def boolean_operator_processing(bool_operator,prevV,nextV):\n",
    "    if bool_operator == \"AND\":\n",
    "        return set(prevV)&set(nextV)\n",
    "    elif bool_operator==\"OR\" :\n",
    "        return set(prevV)|set(nextV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1', 'd2', 'd4'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q='Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© OR Ø¬Ø§Ù…Ø¹Ø©'\n",
    "q=preProcessing(q)\n",
    "q=q.split()\n",
    "v=index[q[0]]\n",
    "u=index[q[2]]\n",
    "boolean_operator_processing(q[1],v,u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
